# from flask import Flask, request, jsonify
# from flask_restful import Api, Resource, reqparse, marshal_with, fields
# from flask_cors import CORS, cross_origin

# import pymongo
# client = pymongo.MongoClient("mongodb://localhost:27017")
# db = client["fakeNews"]

# import re
# import json
# app = Flask(__name__)
# app.config['CORS_HEADERS'] = 'application/json'
# app.app_context().push()
# # CORS(app, support_credentials=True)
# api = Api(app)

# # cors = CORS(app, resources={r"/*": {"origins": "*"}})


# # cors.init_app(app)
# CORS(app)


# # -*- coding: utf-8 -*-
# """fake_news_gpt3_final.ipynb
# Automatically generated by Colaboratory.
# Original file is located at
#     https://colab.research.google.com/drive/1DGtAHo9Koxt2a48RMJMLPKlBrMfOYywF
# """

# #imports 
# #get summary  of news 
# #

# #installations 
# # !pip install nltk 
# # !pip install newspaper3k 
# # !pip install openai
# import nltk
# from newspaper import Article 
# import openai
# import nltk
# from helpers import fact_check

# nltk.download('punkt')
# CORS(app)

# # @cross_origin(supports_credentials=True)
# #********************************* Authenticating a User Query ***********************************
# # ************************************************************************************************
# @app.route('/factcheck',methods=['POST'])
# def verifier():
#     print("Inside the verifier at the backend")
#     data = request.data
#     print("The request body is", data)
#     result = fact_check(data)
#     return jsonify({"result":result}) 

# #********************************* Registering a user ***********************************
# # ************************************************************************************************
# # @app.route("/register", methods=['POST'])
# # def register():
# #     users = db.users
# #     print("Inside the register function at the backend")
# #     data = request.data
# #     res = json.loads(data)
# #     query_user = res["user"]
# #     print(query_user["name"])
# #     username = query_user["name"]
# #     del query_user["name"]
# #     query_user["username"] = username
# #     print("Searching for the user in the database")
# #     query = list(users.find({"username":query_user["username"]}))
# #     if len(query) != 0:
# #         print("USER FOUND!!")
# #         print(list(query))
# #     else:
# #         print("USER DOES NOT EXIST")
# #         inserted_user = dict(users.insert_one(query_user))
# #         print("The inserted user is ")
# #         print(inserted_user)
# #     return jsonify({"MESSAGE":"SUCCESS"})

# if __name__ == "__main__":
#     app.run(debug=True)


from flask import Flask, request, jsonify
from flask_cors import CORS, cross_origin
from flask_restful import Api
from helpers import fact_check
import nltk

import json

import pickle
import numpy as np
import pandas as pd
from flask import Flask, render_template, request
import json
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB
app = Flask(__name__)
CORS(app)  # Initialize CORS for the entire app
api = Api(app)
app.config['CORS_HEADERS'] = 'Content-Type'

nltk.download('punkt')



url = pd.read_csv('./data-set/url_spam_classification.csv')

# Preprocess the data
url['is_spam'] = url.is_spam.apply(str)
url['is_spam'] = url['is_spam'].apply(lambda x: 1 if x == "True" else 0)

# Split data into features and labels
urls = url.iloc[:, 0]
ifSpam = url.iloc[:, 1]

# Tokenization function
def extractUrl(data):
    url = str(data)
    extractSlash = url.split('/')
    result = []
    for i in extractSlash:
        extractDash = str(i).split('-')
        dotExtract = []
        for j in range(0, len(extractDash)):
            extractDot = str(extractDash[j]).split('.')
            dotExtract += extractDot
        result += extractDash + dotExtract
    result = list(set(result))
    return result

# Split data into training and testing sets
urls_train, urls_test, ifSpam_train, ifSpam_test = train_test_split(urls, ifSpam, test_size=0.25)

# Create and train CountVectorizer
cv = CountVectorizer(tokenizer=extractUrl)
features = cv.fit_transform(urls_train)
features_test = cv.transform(urls_test)

# Train Multinomial Naive Bayes model
nbModel = MultinomialNB()
nbModel.fit(features, ifSpam_train)

# Save Multinomial Naive Bayes model using pickle
with open('nbModel.pkl', 'wb') as file:
    pickle.dump(nbModel, file)

# Load Multinomial Naive Bayes model
with open('nbModel.pkl', 'rb') as file:
    loaded_nbModel = pickle.load(file)



@app.route('/predict', methods=['POST'])
@cross_origin()  # Enable CORS for this route

def predict():
    if request.method == 'POST':
        # url = request.form['url']
        data = request.get_json()

        # a = json.loads(data)

        # print(data[""])
        resultret=[]
        var= data["items"]
        for x in var:
            
            input_features = cv.transform([x])  # Use the same CountVectorizer used during training

        # Use the loaded model for prediction
            prediction = loaded_nbModel.predict(input_features)

        # Print the result
            result = "Spam" if prediction == 1 else "Not Spam"
            resultret.append(result)
            print("printing result")
            print(result)
        # for urls in data["items"]:
        # print(data)

        # url = "http://mstats.dare2compete.com/CL0/https:%2F%2Funstop.com%2Fcompetitions%2F842520%2Fregister%3Futm_campaign=site-emails%26utm_medium=d2c-automated%26utm_source=request-to-join-your-team-for-appian-ai-application-challenge-being-organized-by-indian-institute-of-technology-iit-madras/1/0109018c90663b1c-10b00081-4340-431e-883b-f9d599f46629-000000/T0So0ywbGLucNd7m1GCmVDTgSIZLD_4ooocfvyWuR34=134"
        # input_features = cv.transform([url])  # Use the same CountVectorizer used during training

        # # Use the loaded model for prediction
        # prediction = loaded_nbModel.predict(input_features)

        # # Print the result
        # result = "Spam" if prediction == 1 else "Not Spam"
        # print("printing result")
        # print(result)
        # return render_template('result.html', result=result)
        return resultret

# Authenticating a User Query
@app.route('/factcheck', methods=['POST'])
@cross_origin()  # Enable CORS for this route

def verifier():
    print("Inside the verifier at the backend")
    data = request.get_data(as_text=True)
    print("The request body is", data)
    result = fact_check(data)
    return jsonify({"result": result})

if __name__ == "__main__":
    app.run(debug=True)
